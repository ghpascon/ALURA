{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from  sklearn.feature_extraction.text import CountVectorizer\n",
    "from unidecode import unidecode\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import spacy\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format=\"%(asctime)s : - %(message)s\", level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  Após polêmica, Marine Le Pen diz que abomina n...   \n",
      "1  Macron e Le Pen vão ao 2º turno na França, em ...   \n",
      "2  Apesar de larga vitória nas legislativas, Macr...   \n",
      "3  Governo antecipa balanço, e Alckmin anuncia qu...   \n",
      "4  Após queda em maio, a atividade econômica sobe...   \n",
      "\n",
      "                                                text        date   category  \\\n",
      "0  A candidata da direita nacionalista à Presidên...  2017-04-28      mundo   \n",
      "1  O centrista independente Emmanuel Macron e a d...  2017-04-23      mundo   \n",
      "2  As eleições legislativas deste domingo (19) na...  2017-06-19      mundo   \n",
      "3  O número de ocorrências de homicídios dolosos ...  2015-07-24  cotidiano   \n",
      "4  A economia cresceu 0,25% no segundo trimestre,...  2017-08-17    mercado   \n",
      "\n",
      "  subcategory                                               link  \n",
      "0         NaN  http://www1.folha.uol.com.br/mundo/2017/04/187...  \n",
      "1         NaN  http://www1.folha.uol.com.br/mundo/2017/04/187...  \n",
      "2         NaN  http://www1.folha.uol.com.br/mundo/2017/06/189...  \n",
      "3         NaN  http://www1.folha.uol.com.br/cotidiano/2015/07...  \n",
      "4         NaN  http://www1.folha.uol.com.br/mercado/2017/08/1...  \n",
      "                                               title  \\\n",
      "0                                     Grandes irmãos   \n",
      "1  Haddad congela orçamento e suspende emendas de...   \n",
      "2  Proposta de reforma da Fifa tem a divulgação d...   \n",
      "3  Mercado incipiente, internet das coisas conect...   \n",
      "4  Mortes: Psicanalista, estudou o autismo em cri...   \n",
      "\n",
      "                                                text        date   category  \\\n",
      "0  RIO DE JANEIRO - O Brasil, cada vez menos famí...  2017-03-06    colunas   \n",
      "1  O prefeito de São Paulo, Fernando Haddad (PT),...  2016-08-10    colunas   \n",
      "2  A Fifa divulgou, nesta quinta (10), um relatór...  2015-10-09    esporte   \n",
      "3  Bueiros, coleiras, aparelhos hospitalares, ele...  2016-11-09    mercado   \n",
      "4  Toda vez que o grupo de amigos de Silvana Rabe...  2017-02-07  cotidiano   \n",
      "\n",
      "     subcategory                                               link  \n",
      "0      ruycastro  http://www1.folha.uol.com.br/colunas/ruycastro...  \n",
      "1  monicabergamo  http://www1.folha.uol.com.br/colunas/monicaber...  \n",
      "2            NaN  http://www1.folha.uol.com.br/esporte/2015/09/1...  \n",
      "3            NaN  http://www1.folha.uol.com.br/mercado/2016/09/1...  \n",
      "4            NaN  http://www1.folha.uol.com.br/cotidiano/2017/07...  \n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('C:/Users/Usuario/Desktop/word_embeeding_data/treino.csv')\n",
    "test_df = pd.read_csv('C:/Users/Usuario/Desktop/word_embeeding_data/teste.csv')\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPACY\n",
    "https://spacy.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# txt = 'Rio de Janeiro'\n",
    "# doc = nlp(txt)\n",
    "# print(doc[2])\n",
    "# print(doc[1].is_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRATAMENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_treatment(nlp, data, labels = None):\n",
    "    tokens_validos = []\n",
    "    labels_list = []\n",
    "    step = max(1, len(data) // 50)  # Garante que step nunca seja 0\n",
    "    for i, doc in enumerate(nlp.pipe(data, batch_size=1000, n_process=-1)):\n",
    "        if i % step == 0:\n",
    "            print(f\"data {i}/{len(data)}\")\n",
    "        tokens = [token.text.lower() for token in doc if not token.is_stop and token.is_alpha]\n",
    "        if len(tokens) > 2:  # Adiciona apenas se houver mais de 2 palavras\n",
    "            tokens_validos.append(' '.join(tokens))\n",
    "            if labels is not None: labels_list.append(labels[i])\n",
    "\n",
    "    return tokens_validos, labels_list\n",
    "\n",
    "# treat,_ = data_treatment(nlp, ['Rio de 232 Janeiro é uma cidade','cidade cidade cidade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data 0/90000\n",
      "data 1800/90000\n",
      "data 3600/90000\n",
      "data 5400/90000\n",
      "data 7200/90000\n",
      "data 9000/90000\n",
      "data 10800/90000\n",
      "data 12600/90000\n",
      "data 14400/90000\n",
      "data 16200/90000\n",
      "data 18000/90000\n",
      "data 19800/90000\n",
      "data 21600/90000\n",
      "data 23400/90000\n",
      "data 25200/90000\n",
      "data 27000/90000\n",
      "data 28800/90000\n",
      "data 30600/90000\n",
      "data 32400/90000\n",
      "data 34200/90000\n",
      "data 36000/90000\n",
      "data 37800/90000\n",
      "data 39600/90000\n",
      "data 41400/90000\n",
      "data 43200/90000\n",
      "data 45000/90000\n",
      "data 46800/90000\n",
      "data 48600/90000\n",
      "data 50400/90000\n",
      "data 52200/90000\n",
      "data 54000/90000\n",
      "data 55800/90000\n",
      "data 57600/90000\n",
      "data 59400/90000\n",
      "data 61200/90000\n",
      "data 63000/90000\n",
      "data 64800/90000\n",
      "data 66600/90000\n",
      "data 68400/90000\n",
      "data 70200/90000\n",
      "data 72000/90000\n",
      "data 73800/90000\n",
      "data 75600/90000\n",
      "data 77400/90000\n",
      "data 79200/90000\n",
      "data 81000/90000\n",
      "data 82800/90000\n",
      "data 84600/90000\n",
      "data 86400/90000\n",
      "data 88200/90000\n",
      "                                               title   category\n",
      "0  polêmica marine le pen abomina negacionistas h...      mundo\n",
      "1  macron le pen turno frança revés siglas tradic...      mundo\n",
      "2  apesar larga vitória legislativas macron terá ...      mundo\n",
      "3  governo antecipa balanço alckmin anuncia queda...  cotidiano\n",
      "4       queda maio atividade econômica sobe junho bc    mercado\n"
     ]
    }
   ],
   "source": [
    "train_df_treat=pd.DataFrame()\n",
    "\n",
    "train_df_treat['title'], train_df_treat['category'] = data_treatment(nlp, train_df['title'], train_df['category'])\n",
    "\n",
    "print(train_df_treat.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data 0/20513\n",
      "data 410/20513\n",
      "data 820/20513\n",
      "data 1230/20513\n",
      "data 1640/20513\n",
      "data 2050/20513\n",
      "data 2460/20513\n",
      "data 2870/20513\n",
      "data 3280/20513\n",
      "data 3690/20513\n",
      "data 4100/20513\n",
      "data 4510/20513\n",
      "data 4920/20513\n",
      "data 5330/20513\n",
      "data 5740/20513\n",
      "data 6150/20513\n",
      "data 6560/20513\n",
      "data 6970/20513\n",
      "data 7380/20513\n",
      "data 7790/20513\n",
      "data 8200/20513\n",
      "data 8610/20513\n",
      "data 9020/20513\n",
      "data 9430/20513\n",
      "data 9840/20513\n",
      "data 10250/20513\n",
      "data 10660/20513\n",
      "data 11070/20513\n",
      "data 11480/20513\n",
      "data 11890/20513\n",
      "data 12300/20513\n",
      "data 12710/20513\n",
      "data 13120/20513\n",
      "data 13530/20513\n",
      "data 13940/20513\n",
      "data 14350/20513\n",
      "data 14760/20513\n",
      "data 15170/20513\n",
      "data 15580/20513\n",
      "data 15990/20513\n",
      "data 16400/20513\n",
      "data 16810/20513\n",
      "data 17220/20513\n",
      "data 17630/20513\n",
      "data 18040/20513\n",
      "data 18450/20513\n",
      "data 18860/20513\n",
      "data 19270/20513\n",
      "data 19680/20513\n",
      "data 20090/20513\n",
      "data 20500/20513\n",
      "                                               title   category\n",
      "0  haddad congela orçamento suspende emendas vere...    colunas\n",
      "1  proposta reforma fifa divulgação salário cartolas    esporte\n",
      "2  mercado incipiente internet coisas conecta bue...    mercado\n",
      "3       mortes psicanalista estudou autismo crianças  cotidiano\n",
      "4                    pra entender estupidez maradona    esporte\n"
     ]
    }
   ],
   "source": [
    "test_df_treat=pd.DataFrame()\n",
    "\n",
    "test_df_treat['title'], test_df_treat['category'] = data_treatment(nlp, test_df['title'], test_df['category'])\n",
    "\n",
    "print(test_df_treat.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 18:37:34,569 : - Callbacks are no longer retained by the model, so must be provided whenever training is triggered, as in initialization with a corpus or calling `train()`. The callbacks provided in this initialization without triggering train will be ignored.\n",
      "2025-01-04 18:37:34,572 : - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=300, alpha=0.03>', 'datetime': '2025-01-04T18:37:34.571473', 'gensim': '4.3.3', 'python': '3.9.0 (tags/v3.9.0:9cf6752, Oct  5 2020, 15:34:40) [MSC v.1927 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n",
      "2025-01-04 18:37:35,085 : - collecting all words and their counts\n",
      "2025-01-04 18:37:35,086 : - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2025-01-04 18:37:35,129 : - PROGRESS: at sentence #10000, processed 63841 words, keeping 14987 word types\n",
      "2025-01-04 18:37:35,186 : - PROGRESS: at sentence #20000, processed 127676 words, keeping 21031 word types\n",
      "2025-01-04 18:37:35,231 : - PROGRESS: at sentence #30000, processed 191537 words, keeping 25492 word types\n",
      "2025-01-04 18:37:35,287 : - PROGRESS: at sentence #40000, processed 255264 words, keeping 29051 word types\n",
      "2025-01-04 18:37:35,341 : - PROGRESS: at sentence #50000, processed 319240 words, keeping 31962 word types\n",
      "2025-01-04 18:37:35,400 : - PROGRESS: at sentence #60000, processed 383548 words, keeping 34516 word types\n",
      "2025-01-04 18:37:35,462 : - PROGRESS: at sentence #70000, processed 447605 words, keeping 36716 word types\n",
      "2025-01-04 18:37:35,523 : - PROGRESS: at sentence #80000, processed 511600 words, keeping 38810 word types\n",
      "2025-01-04 18:37:35,546 : - collected 39689 word types from a corpus of 540186 raw words and 84465 sentences\n",
      "2025-01-04 18:37:35,547 : - Creating a fresh vocabulary\n",
      "2025-01-04 18:37:35,682 : - Word2Vec lifecycle event {'msg': 'effective_min_count=3 retains 18184 unique words (45.82% of original 39689, drops 21505)', 'datetime': '2025-01-04T18:37:35.682220', 'gensim': '4.3.3', 'python': '3.9.0 (tags/v3.9.0:9cf6752, Oct  5 2020, 15:34:40) [MSC v.1927 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2025-01-04 18:37:35,684 : - Word2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 513044 word corpus (94.98% of original 540186, drops 27142)', 'datetime': '2025-01-04T18:37:35.684229', 'gensim': '4.3.3', 'python': '3.9.0 (tags/v3.9.0:9cf6752, Oct  5 2020, 15:34:40) [MSC v.1927 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2025-01-04 18:37:35,867 : - deleting the raw counts dictionary of 39689 items\n",
      "2025-01-04 18:37:35,870 : - sample=0.001 downsamples 8 most-common words\n",
      "2025-01-04 18:37:35,875 : - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 504278.90908523684 word corpus (98.3%% of prior 513044)', 'datetime': '2025-01-04T18:37:35.875313', 'gensim': '4.3.3', 'python': '3.9.0 (tags/v3.9.0:9cf6752, Oct  5 2020, 15:34:40) [MSC v.1927 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2025-01-04 18:37:36,253 : - estimated required memory for 18184 words and 300 dimensions: 52733600 bytes\n",
      "2025-01-04 18:37:36,255 : - resetting layer weights\n",
      "2025-01-04 18:37:36,324 : - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-01-04T18:37:36.324901', 'gensim': '4.3.3', 'python': '3.9.0 (tags/v3.9.0:9cf6752, Oct  5 2020, 15:34:40) [MSC v.1927 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "sg=0 -> cbow\n",
    "sg=1 -> skipgram\n",
    "\n",
    "window -> contexto das palavras(qtd antes e depois)\n",
    "\n",
    "vector_size -> tamanho da matriz\n",
    "\n",
    "min_count -> evita erros de digitação com um minimo necessário de repetição\n",
    "\n",
    "alpha -> learning rate\n",
    "min_alpha -> suavização do lr\n",
    "'''\n",
    "\n",
    "class callback(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        if self.epoch == 0:\n",
    "            print('Loss após a época {}: {}'.format(self.epoch, loss))\n",
    "        else:\n",
    "            print('Loss após a época {}: {}'.format(self.epoch, loss- self.loss_previous_step))\n",
    "        self.epoch += 1\n",
    "        self.loss_previous_step = loss\n",
    "\n",
    "model = Word2Vec(\n",
    "    sg = 1,\n",
    "    window=5,\n",
    "    vector_size=300,\n",
    "    min_count=3,\n",
    "    alpha=0.03,\n",
    "    min_alpha=0.007,\n",
    "    compute_loss = True,\n",
    "    callbacks=[callback()]\n",
    "    )\n",
    "\n",
    "token_list = [txt.split(' ') for txt in train_df_treat['title'].drop_duplicates().dropna()]\n",
    "model.build_vocab(token_list, progress_per=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 18:37:36,356 : - Word2Vec lifecycle event {'msg': 'training model with 3 workers on 18184 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-01-04T18:37:36.356906', 'gensim': '4.3.3', 'python': '3.9.0 (tags/v3.9.0:9cf6752, Oct  5 2020, 15:34:40) [MSC v.1927 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2025-01-04 18:37:37,562 : - EPOCH 0 - PROGRESS: at 24.10% examples, 103762 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:37:38,699 : - EPOCH 0 - PROGRESS: at 51.92% examples, 113292 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:37:39,704 : - EPOCH 0 - PROGRESS: at 79.61% examples, 121162 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:37:40,431 : - EPOCH 0: training on 540186 raw words (504205 effective words) took 4.0s, 124849 effective words/s\n",
      "2025-01-04 18:37:41,626 : - EPOCH 1 - PROGRESS: at 24.10% examples, 103156 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:37:42,817 : - EPOCH 1 - PROGRESS: at 51.92% examples, 110435 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:37:43,832 : - EPOCH 1 - PROGRESS: at 66.69% examples, 99335 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:37:44,860 : - EPOCH 1 - PROGRESS: at 87.01% examples, 99458 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:37:45,368 : - EPOCH 1: training on 540186 raw words (504359 effective words) took 4.9s, 102544 effective words/s\n",
      "2025-01-04 18:37:46,408 : - EPOCH 2 - PROGRESS: at 18.54% examples, 92719 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:37:47,434 : - EPOCH 2 - PROGRESS: at 42.66% examples, 105614 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:37:48,459 : - EPOCH 2 - PROGRESS: at 66.69% examples, 109856 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:37:49,558 : - EPOCH 2 - PROGRESS: at 90.68% examples, 109987 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:37:49,812 : - EPOCH 2: training on 540186 raw words (504287 effective words) took 4.4s, 114305 effective words/s\n",
      "2025-01-04 18:37:50,922 : - EPOCH 3 - PROGRESS: at 24.10% examples, 111844 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:37:51,927 : - EPOCH 3 - PROGRESS: at 46.36% examples, 111602 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:37:53,042 : - EPOCH 3 - PROGRESS: at 74.07% examples, 116481 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:37:53,972 : - EPOCH 3: training on 540186 raw words (504389 effective words) took 4.1s, 121952 effective words/s\n",
      "2025-01-04 18:37:55,162 : - EPOCH 4 - PROGRESS: at 24.10% examples, 104550 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:37:56,195 : - EPOCH 4 - PROGRESS: at 48.22% examples, 110560 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:37:57,273 : - EPOCH 4 - PROGRESS: at 70.38% examples, 108356 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:37:58,283 : - EPOCH 4 - PROGRESS: at 92.53% examples, 108956 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:37:58,556 : - EPOCH 4: training on 540186 raw words (504282 effective words) took 4.6s, 110710 effective words/s\n",
      "2025-01-04 18:37:59,624 : - EPOCH 5 - PROGRESS: at 18.54% examples, 88740 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:38:00,674 : - EPOCH 5 - PROGRESS: at 37.08% examples, 88864 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:38:02,019 : - EPOCH 5 - PROGRESS: at 59.33% examples, 86671 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:38:03,131 : - EPOCH 5 - PROGRESS: at 81.45% examples, 90088 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:38:04,090 : - EPOCH 5: training on 540186 raw words (504281 effective words) took 5.5s, 91403 effective words/s\n",
      "2025-01-04 18:38:05,145 : - EPOCH 6 - PROGRESS: at 16.70% examples, 82416 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:38:06,190 : - EPOCH 6 - PROGRESS: at 29.67% examples, 72336 words/s, in_qsize 5, out_qsize 1\n",
      "2025-01-04 18:38:07,314 : - EPOCH 6 - PROGRESS: at 46.36% examples, 73171 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:38:08,336 : - EPOCH 6 - PROGRESS: at 64.84% examples, 77574 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:38:09,359 : - EPOCH 6 - PROGRESS: at 81.45% examples, 78460 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:38:10,369 : - EPOCH 6 - PROGRESS: at 100.00% examples, 80778 words/s, in_qsize 0, out_qsize 1\n",
      "2025-01-04 18:38:10,371 : - EPOCH 6: training on 540186 raw words (504274 effective words) took 6.2s, 80753 effective words/s\n",
      "2025-01-04 18:38:11,662 : - EPOCH 7 - PROGRESS: at 18.54% examples, 75735 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:38:12,662 : - EPOCH 7 - PROGRESS: at 35.23% examples, 79430 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:38:13,703 : - EPOCH 7 - PROGRESS: at 51.92% examples, 79822 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:38:14,708 : - EPOCH 7 - PROGRESS: at 70.36% examples, 82902 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:38:15,778 : - EPOCH 7 - PROGRESS: at 79.61% examples, 75047 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:38:16,779 : - EPOCH 7 - PROGRESS: at 96.24% examples, 76429 words/s, in_qsize 3, out_qsize 0\n",
      "2025-01-04 18:38:16,829 : - EPOCH 7: training on 540186 raw words (504318 effective words) took 6.4s, 78796 effective words/s\n",
      "2025-01-04 18:38:18,280 : - EPOCH 8 - PROGRESS: at 18.55% examples, 65327 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:38:19,338 : - EPOCH 8 - PROGRESS: at 37.08% examples, 75103 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:38:20,371 : - EPOCH 8 - PROGRESS: at 53.76% examples, 76919 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:38:21,394 : - EPOCH 8 - PROGRESS: at 70.36% examples, 78045 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:38:22,439 : - EPOCH 8 - PROGRESS: at 85.16% examples, 76805 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:38:23,261 : - EPOCH 8: training on 540186 raw words (504244 effective words) took 6.4s, 78675 effective words/s\n",
      "2025-01-04 18:38:24,364 : - EPOCH 9 - PROGRESS: at 12.97% examples, 60506 words/s, in_qsize 4, out_qsize 1\n",
      "2025-01-04 18:38:25,371 : - EPOCH 9 - PROGRESS: at 31.51% examples, 75999 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:38:26,494 : - EPOCH 9 - PROGRESS: at 51.92% examples, 81368 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:38:27,523 : - EPOCH 9 - PROGRESS: at 68.54% examples, 81426 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:38:28,540 : - EPOCH 9 - PROGRESS: at 90.68% examples, 86971 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:38:28,993 : - EPOCH 9: training on 540186 raw words (504222 effective words) took 5.7s, 88303 effective words/s\n",
      "2025-01-04 18:38:30,112 : - EPOCH 10 - PROGRESS: at 18.54% examples, 85970 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:38:31,134 : - EPOCH 10 - PROGRESS: at 40.80% examples, 97473 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:38:32,188 : - EPOCH 10 - PROGRESS: at 62.99% examples, 100352 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:38:33,304 : - EPOCH 10 - PROGRESS: at 87.01% examples, 102557 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:38:33,843 : - EPOCH 10: training on 540186 raw words (504315 effective words) took 4.8s, 104695 effective words/s\n",
      "2025-01-04 18:38:35,108 : - EPOCH 11 - PROGRESS: at 24.10% examples, 97414 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:38:36,116 : - EPOCH 11 - PROGRESS: at 48.22% examples, 107717 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:38:37,312 : - EPOCH 11 - PROGRESS: at 74.07% examples, 108233 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:38:38,340 : - EPOCH 11 - PROGRESS: at 96.24% examples, 108403 words/s, in_qsize 3, out_qsize 0\n",
      "2025-01-04 18:38:38,368 : - EPOCH 11: training on 540186 raw words (504307 effective words) took 4.5s, 111945 effective words/s\n",
      "2025-01-04 18:38:39,400 : - EPOCH 12 - PROGRESS: at 22.25% examples, 109944 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:38:40,430 : - EPOCH 12 - PROGRESS: at 42.66% examples, 104791 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:38:41,451 : - EPOCH 12 - PROGRESS: at 66.69% examples, 109429 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:38:42,514 : - EPOCH 12 - PROGRESS: at 81.45% examples, 99362 words/s, in_qsize 6, out_qsize 1\n",
      "2025-01-04 18:38:43,216 : - EPOCH 12: training on 540186 raw words (504297 effective words) took 4.8s, 104293 effective words/s\n",
      "2025-01-04 18:38:44,470 : - EPOCH 13 - PROGRESS: at 24.10% examples, 99482 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:38:45,493 : - EPOCH 13 - PROGRESS: at 50.08% examples, 112348 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:38:46,592 : - EPOCH 13 - PROGRESS: at 68.54% examples, 103329 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:38:47,593 : - EPOCH 13 - PROGRESS: at 83.30% examples, 96703 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:38:48,524 : - EPOCH 13: training on 540186 raw words (504304 effective words) took 5.3s, 95624 effective words/s\n",
      "2025-01-04 18:38:49,556 : - EPOCH 14 - PROGRESS: at 7.41% examples, 36604 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:38:50,630 : - EPOCH 14 - PROGRESS: at 24.10% examples, 57972 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:38:51,665 : - EPOCH 14 - PROGRESS: at 46.36% examples, 74540 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:38:52,669 : - EPOCH 14 - PROGRESS: at 64.84% examples, 79018 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:38:53,673 : - EPOCH 14 - PROGRESS: at 85.16% examples, 83570 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:38:54,346 : - EPOCH 14: training on 540186 raw words (504311 effective words) took 5.8s, 86791 effective words/s\n",
      "2025-01-04 18:38:55,527 : - EPOCH 15 - PROGRESS: at 18.54% examples, 81367 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:38:56,568 : - EPOCH 15 - PROGRESS: at 37.08% examples, 85309 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:38:57,637 : - EPOCH 15 - PROGRESS: at 51.92% examples, 80221 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:38:58,781 : - EPOCH 15 - PROGRESS: at 68.54% examples, 78438 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:38:59,824 : - EPOCH 15 - PROGRESS: at 81.45% examples, 75411 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:39:00,836 : - EPOCH 15 - PROGRESS: at 94.40% examples, 73710 words/s, in_qsize 4, out_qsize 0\n",
      "2025-01-04 18:39:01,103 : - EPOCH 15: training on 540186 raw words (504204 effective words) took 6.7s, 74993 effective words/s\n",
      "2025-01-04 18:39:02,155 : - EPOCH 16 - PROGRESS: at 14.83% examples, 72966 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:39:03,192 : - EPOCH 16 - PROGRESS: at 29.67% examples, 72441 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:39:04,218 : - EPOCH 16 - PROGRESS: at 46.36% examples, 75577 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:39:05,245 : - EPOCH 16 - PROGRESS: at 66.69% examples, 81653 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:39:06,257 : - EPOCH 16 - PROGRESS: at 79.61% examples, 78289 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:39:07,264 : - EPOCH 16 - PROGRESS: at 100.00% examples, 82239 words/s, in_qsize 0, out_qsize 1\n",
      "2025-01-04 18:39:07,267 : - EPOCH 16: training on 540186 raw words (504261 effective words) took 6.1s, 82200 effective words/s\n",
      "2025-01-04 18:39:08,514 : - EPOCH 17 - PROGRESS: at 18.54% examples, 76797 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:39:09,542 : - EPOCH 17 - PROGRESS: at 37.09% examples, 83234 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:39:10,667 : - EPOCH 17 - PROGRESS: at 51.92% examples, 77587 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:39:11,681 : - EPOCH 17 - PROGRESS: at 68.54% examples, 78796 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:39:12,692 : - EPOCH 17 - PROGRESS: at 85.16% examples, 79601 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:39:13,411 : - EPOCH 17: training on 540186 raw words (504350 effective words) took 6.1s, 82506 effective words/s\n",
      "2025-01-04 18:39:14,554 : - EPOCH 18 - PROGRESS: at 20.40% examples, 91582 words/s, in_qsize 4, out_qsize 1\n",
      "2025-01-04 18:39:15,618 : - EPOCH 18 - PROGRESS: at 40.80% examples, 93948 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:39:16,867 : - EPOCH 18 - PROGRESS: at 62.99% examples, 92419 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:39:18,025 : - EPOCH 18 - PROGRESS: at 85.16% examples, 93491 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:39:18,728 : - EPOCH 18: training on 540186 raw words (504271 effective words) took 5.3s, 95239 effective words/s\n",
      "2025-01-04 18:39:19,778 : - EPOCH 19 - PROGRESS: at 18.54% examples, 90863 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:39:20,791 : - EPOCH 19 - PROGRESS: at 42.66% examples, 105247 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:39:21,865 : - EPOCH 19 - PROGRESS: at 64.84% examples, 104844 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:39:22,877 : - EPOCH 19 - PROGRESS: at 88.86% examples, 108544 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:39:23,434 : - EPOCH 19: training on 540186 raw words (504208 effective words) took 4.7s, 107653 effective words/s\n",
      "2025-01-04 18:39:24,572 : - EPOCH 20 - PROGRESS: at 18.54% examples, 84334 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:39:25,652 : - EPOCH 20 - PROGRESS: at 40.80% examples, 93845 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:39:26,712 : - EPOCH 20 - PROGRESS: at 64.84% examples, 100586 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:39:27,719 : - EPOCH 20 - PROGRESS: at 88.86% examples, 105295 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:39:28,112 : - EPOCH 20: training on 540186 raw words (504398 effective words) took 4.6s, 108498 effective words/s\n",
      "2025-01-04 18:39:29,236 : - EPOCH 21 - PROGRESS: at 24.10% examples, 111063 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:39:30,280 : - EPOCH 21 - PROGRESS: at 46.36% examples, 109151 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:39:31,506 : - EPOCH 21 - PROGRESS: at 68.54% examples, 102663 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:39:32,694 : - EPOCH 21 - PROGRESS: at 90.68% examples, 100455 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:39:33,010 : - EPOCH 21: training on 540186 raw words (504239 effective words) took 4.9s, 103588 effective words/s\n",
      "2025-01-04 18:39:34,034 : - EPOCH 22 - PROGRESS: at 18.54% examples, 92859 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:39:35,065 : - EPOCH 22 - PROGRESS: at 42.66% examples, 105504 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:39:36,231 : - EPOCH 22 - PROGRESS: at 68.54% examples, 107855 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:39:37,372 : - EPOCH 22 - PROGRESS: at 96.23% examples, 111749 words/s, in_qsize 3, out_qsize 0\n",
      "2025-01-04 18:39:37,453 : - EPOCH 22: training on 540186 raw words (504236 effective words) took 4.4s, 114011 effective words/s\n",
      "2025-01-04 18:39:38,685 : - EPOCH 23 - PROGRESS: at 24.10% examples, 102467 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:39:39,953 : - EPOCH 23 - PROGRESS: at 46.36% examples, 95114 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:39:40,990 : - EPOCH 23 - PROGRESS: at 63.01% examples, 90957 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:39:42,166 : - EPOCH 23 - PROGRESS: at 85.16% examples, 92009 words/s, in_qsize 4, out_qsize 1\n",
      "2025-01-04 18:39:43,047 : - EPOCH 23: training on 540186 raw words (504252 effective words) took 5.5s, 90928 effective words/s\n",
      "2025-01-04 18:39:44,305 : - EPOCH 24 - PROGRESS: at 18.55% examples, 75133 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:39:45,357 : - EPOCH 24 - PROGRESS: at 35.23% examples, 77280 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:39:46,419 : - EPOCH 24 - PROGRESS: at 57.46% examples, 86184 words/s, in_qsize 6, out_qsize 1\n",
      "2025-01-04 18:39:47,422 : - EPOCH 24 - PROGRESS: at 79.61% examples, 92062 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:39:48,326 : - EPOCH 24: training on 540186 raw words (504467 effective words) took 5.3s, 95818 effective words/s\n",
      "2025-01-04 18:39:49,741 : - EPOCH 25 - PROGRESS: at 18.54% examples, 78777 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:39:50,931 : - EPOCH 25 - PROGRESS: at 40.80% examples, 86493 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:39:51,945 : - EPOCH 25 - PROGRESS: at 64.84% examples, 96391 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:39:52,960 : - EPOCH 25 - PROGRESS: at 90.68% examples, 103859 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:39:53,181 : - EPOCH 25: training on 540186 raw words (504356 effective words) took 4.6s, 109055 effective words/s\n",
      "2025-01-04 18:39:54,225 : - EPOCH 26 - PROGRESS: at 24.10% examples, 117839 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:39:55,386 : - EPOCH 26 - PROGRESS: at 46.36% examples, 106514 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:39:56,495 : - EPOCH 26 - PROGRESS: at 61.16% examples, 93422 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:39:57,596 : - EPOCH 26 - PROGRESS: at 79.61% examples, 91230 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:39:58,526 : - EPOCH 26: training on 540186 raw words (504447 effective words) took 5.3s, 94626 effective words/s\n",
      "2025-01-04 18:39:59,636 : - EPOCH 27 - PROGRESS: at 18.54% examples, 86129 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:40:01,045 : - EPOCH 27 - PROGRESS: at 40.81% examples, 82382 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:40:02,212 : - EPOCH 27 - PROGRESS: at 57.46% examples, 79029 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:40:03,331 : - EPOCH 27 - PROGRESS: at 74.07% examples, 78101 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:40:04,394 : - EPOCH 27 - PROGRESS: at 100.00% examples, 86299 words/s, in_qsize 0, out_qsize 1\n",
      "2025-01-04 18:40:04,397 : - EPOCH 27: training on 540186 raw words (504260 effective words) took 5.8s, 86257 effective words/s\n",
      "2025-01-04 18:40:05,823 : - EPOCH 28 - PROGRESS: at 18.54% examples, 78318 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:40:06,878 : - EPOCH 28 - PROGRESS: at 40.80% examples, 91393 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:40:07,977 : - EPOCH 28 - PROGRESS: at 68.54% examples, 103194 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:40:09,055 : - EPOCH 28 - PROGRESS: at 96.24% examples, 109715 words/s, in_qsize 3, out_qsize 0\n",
      "2025-01-04 18:40:09,150 : - EPOCH 28: training on 540186 raw words (504349 effective words) took 4.5s, 111591 effective words/s\n",
      "2025-01-04 18:40:10,257 : - EPOCH 29 - PROGRESS: at 14.83% examples, 74301 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:40:11,296 : - EPOCH 29 - PROGRESS: at 29.67% examples, 73044 words/s, in_qsize 6, out_qsize 0\n",
      "2025-01-04 18:40:12,396 : - EPOCH 29 - PROGRESS: at 48.22% examples, 77194 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:40:13,423 : - EPOCH 29 - PROGRESS: at 62.99% examples, 76093 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:40:14,496 : - EPOCH 29 - PROGRESS: at 75.91% examples, 72964 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:40:15,712 : - EPOCH 29 - PROGRESS: at 92.53% examples, 72245 words/s, in_qsize 5, out_qsize 0\n",
      "2025-01-04 18:40:16,118 : - EPOCH 29: training on 540186 raw words (504304 effective words) took 6.9s, 73444 effective words/s\n",
      "2025-01-04 18:40:16,121 : - Word2Vec lifecycle event {'msg': 'training on 16205580 raw words (15128997 effective words) took 159.8s, 94697 effective words/s', 'datetime': '2025-01-04T18:40:16.120662', 'gensim': '4.3.3', 'python': '3.9.0 (tags/v3.9.0:9cf6752, Oct  5 2020, 15:34:40) [MSC v.1927 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15128997, 16205580)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(\n",
    "    token_list, \n",
    "    total_examples=model.corpus_count,\n",
    "    epochs=30\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('antitruste', 0.46200889348983765),\n",
       " ('alphabet', 0.4578295052051544),\n",
       " ('facebook', 0.4214685559272766),\n",
       " ('difusão', 0.41609641909599304),\n",
       " ('android', 0.4134223759174347),\n",
       " ('waze', 0.4115716218948364),\n",
       " ('apple', 0.4096739888191223),\n",
       " ('ipo', 0.39929017424583435),\n",
       " ('reguladores', 0.39840492606163025),\n",
       " ('abusivo', 0.39228248596191406)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('google')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 18:42:34,378 : - storing 18184x300 projection weights into model/sg_model.txt\n"
     ]
    }
   ],
   "source": [
    "model.wv.save_word2vec_format('model/sg_model.txt', binary=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
